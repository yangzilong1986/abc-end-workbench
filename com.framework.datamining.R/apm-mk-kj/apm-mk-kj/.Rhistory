library(elasticnet)
library(caret)
library(lars)
library(MASS)
library(pls)
library(stats)
library(AppliedPredictiveModeling)
data(solubility)
ls(pattern = "^solT")
set.seed(2)
sample(names(solTrainX), 8)
ctrl <- trainControl(method = "cv", number = 10)
trainingData <- solTrainXtrans
trainingData$Solubility <- solTrainY
head(trainingData)
lmFitAllPredictors <- lm(Solubility ~ ., data = trainingData)
summary(lmFitAllPredictors)
lmPred1 <- predict(lmFitAllPredictors, solTestXtrans)
head(lmPred1)
lmValues1 <- data.frame(obs = solTestY, pred = lmPred1)
defaultSummary(lmValues1)
rlmFitAllPredictors <- rlm(Solubility ~ ., data = trainingData)
set.seed(100)
lmFit1 <- train(x = solTrainXtrans, y = solTrainY,
method = "lm", trControl = ctrl)
lmFit1
xyplot(solTrainY ~ predict(lmFit1),
#plot the points (type = 'p') and a background grid ('g')
type = c("p", "g"),
xlab = "Predicted", ylab = "Observed")
xyplot(resid(lmFit1) ~ predict(lmFit1),
type = c("p", "g"),
xlab = "Predicted", ylab = "Residuals")
corThresh <- .9
tooHigh <- findCorrelation(cor(solTrainXtrans), corThresh)
corrPred <- names(solTrainXtrans)[tooHigh]
trainXfiltered <- solTrainXtrans[, -tooHigh]
set.seed(100)
lmFiltered <- train(solTrainXtrans, solTrainY, method = "lm",trControl = ctrl)
lmFiltered
set.seed(100)
rlmPCA <- train(solTrainXtrans, solTrainY,method = "rlm",preProcess = "pca",trControl = ctrl)
rlmPCA
rlmPCA <- train(solTrainXtrans, solTrainY,method = "rlm",preProcess = "pca",trControl = ctrl)
rlmPCA
rlmPCA
set.seed(100)
rlmPCA <- train(solTrainXtrans, solTrainY,method = "rlm",preProcess = "pca",trControl = ctrl)
rlmPCA
plsFit <- plsr(Solubility ~ ., data = trainingData)
predict(plsFit, solTestXtrans[1:5,], ncomp = 1:2)
set.seed(100)
plsTune <- train(solTrainXtrans, solTrainY,
method = "pls",
## The default tuning grid evaluates
## components 1... tuneLength
tuneLength = 20,
trControl = ctrl,
preProc = c("center", "scale"))
plsTune
plot(plsTune$results$ncomp,plsTune$results$RMSE,
xlab = "component",ylab = "RMSE(Cross-Validation)",
main = "PLS", sub="NI-PALS",
#xlim=c(0, 20), ylim=c(0, 2),
col="red",type="b",lty-1)
plot(plsTune$results$ncomp,plsTune$results$RMSE,
xlab = "component",ylab = "RMSE(Cross-Validation)",
main = "PLS", sub="NI-PALS",
#xlim=c(0, 20), ylim=c(0, 2),
col="red",type="b",lty-1)
plot(plsTune$results$ncomp,plsTune$results$RMSE,
xlab = "component",ylab = "RMSE(Cross-Validation)",
main = "PLS", sub="NI-PALS",
#xlim=c(0, 20), ylim=c(0, 2),
col="red",type="b",lty=1)
legend("topright", inset=.05, c("pls"), lty=c(1),col=c("red"))
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.001)
ridgePred <- predict(ridgeModel, newx = as.matrix(solTestXtrans),
s = 1, mode = "fraction",type = "fit")
head(ridgePred$fit)
ridgeGrid <- data.frame(.lambda = seq(0, .1, length = 15))
set.seed(100)
ridgeRegFit <- train(solTrainXtrans, solTrainY,
method = "ridge",
## Fir the model over many penalty values
tuneGrid = ridgeGrid,
trControl = ctrl,
## put the predictors on the same scale
preProc = c("center", "scale"))
ridgeRegFit
plot(ridgeRegFit)
ridgePred <- predict(ridgeModel, newx = as.matrix(solTestXtrans),
s = 1, mode = "fraction",type = "fit")
head(ridgePred$fit)
ridgeGrid <- data.frame(.lambda = seq(0, .1, length = 15))
plot(ridgePred)
plot(solTestXtrans,ridgePred$fit)
View(solTrainX)
plot(ridgePred$mode,ridgePred$fit)
plot(ridgeModel$penalty,ridgePred$fit)
ridgeModel$penalty
head(ridgePred$fit)
ridgeModel$lambda
summary(ridgeModel)
plot(ridgeModel$penalty,ridgeModel$Cp)
ridgeModel$penalty
plot(ridgeModel$penalty,ridgeModel$Cp,type=b)
plot(ridgeModel$penalty,ridgeModel$Cp,type=b)
plot(ridgeModel$penalty,ridgeModel$Cp,type="b")
plot(predict(ridgeModel, type="response"),
residuals(ridgeModel, type= "deviance"))
plot(predict(ridgeModel$fit, type="response"),
residuals(ridgeModel$fit, type= "deviance"))
plot(ridgePred$fit,
residuals(ridgePred$fit, type= "deviance"))
head(ridgePred$fit)
residuals(ridgePred$fit, type= "deviance")
residuals(ridgePred, type= "deviance")
residuals(ridgeModel, type= "deviance")
coefficients(ridgeModel)
plot(plsTune$results$ncomp,plsTune$results$RMSE,
xlab = "component",ylab = "RMSE(Cross-Validation)",
main = "PLS", sub="NI-PALS",
#xlim=c(0, 20), ylim=c(0, 2),
col="red",type="b",lty=1)
head(ridgePred$fit)
library(AppliedPredictiveModeling)
data(solubility)
ls(pattern = "^solT")
set.seed(2)
sample(names(solTrainX), 8)
ctrl <- trainControl(method = "cv", number = 10)
library(elasticnet)
library(caret)
library(lars)
library(MASS)
library(pls)
library(stats)
library(AppliedPredictiveModeling)
data(solubility)
ls(pattern = "^solT")
set.seed(2)
sample(names(solTrainX), 8)
ctrl <- trainControl(method = "cv", number = 10)
trainingData <- solTrainXtrans
trainingData$Solubility <- solTrainY
head(trainingData)
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.001)
plot(ridgeModel)
ridgeModel
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.1)
ridgeModel
plot(ridgeModel)
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.0001)
ridgeModel
plot(ridgeModel)
ridgePred <- predict(ridgeModel, newx = as.matrix(solTestXtrans),
s = 1, mode = "fraction",type = "fit")
head(ridgePred$fit)
plot(ridgePred$fit)
coefficients(ridgePred$fit)
coefficients(ridgePred)
plot(ridgePred)
head(ridgePred$fit)
plot(ridgeModel)
plot(ridgeRegFit)
plot(ridgeRegFit$results$lambda,ridgeRegFit$results$RMSE,
xlab = "lambda",ylab = "RMSE(Cross-Validation)",
main = "ridge", sub="NI-PALS",
#xlim=c(0, 20), ylim=c(0, 2),
col="blue",type="b",lty=1)
legend("topright", inset=.05, c("ridge"), lty=c(1),col=c("blue"))
plot(ridgeRegFit)
plot(ridgeModel)
plot(ridgePred$fit)
head
head(ridgePred$fit)
ridgePred$fit
dim(ridgePred$fit)
dim(ridgePred)
tail(ridgePred)
tail(ridgePred)
coefficients(ridgePred)
coefficients(ridgeModel)
plot(ridgeModel)
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.00000001)
ridgeModel
plot(ridgeModel)
ridgePred <- predict(ridgeModel, newx = as.matrix(solTestXtrans),
s = 1, mode = "fraction",type = "fit")
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.01)
ridgeModel
plot(ridgeModel)
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.1)
ridgeModel
plot(ridgeModel)
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY)
ridgeModel
plot(ridgeModel)
ridgePred <- predict(ridgeModel, newx = as.matrix(solTestXtrans),
s = 1, mode = "fraction",type = "fit")
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.001)
ridgeModel
plot(ridgeModel)
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.00001)
ridgeModel
plot(ridgeModel)
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.001)
plot(ridgeModel)
ridgeModel
plot(ridgeModel,xlab="Penalty",ylab="Sandardized Cofficient")
plot(ridgeModel,xlab="Penalty",ylab="Sandardized Cofficient")
plot(ridgeModel)
debugSource('D:/DevR/apm-mk-kj/apm-mk-kj/ridge-linear-regression.R', encoding = 'UTF-8')
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
segData <- subset(segmentationOriginal, Case == "Train")
cellID <- segData$Cell
class <- segData$Class
case <- segData$Case
segData <- segData[, -(1:3)]
statusColNum <- grep("Status", names(segData))
statusColNum
segData <- segData[, -statusColNum]
library(e1071)
skewness(segData$AngleCh1)
skewValues <- apply(segData, 2, skewness)
head(skewValues)
Ch1AreaTrans <- BoxCoxTrans(segData$AreaCh1)
Ch1AreaTrans
head(segData$AreaCh1)
predict(Ch1AreaTrans, head(segData$AreaCh1))
predict(Ch1AreaTrans, head(segData$AreaCh1))
pcaObject <- prcomp(segData,
center = TRUE, scale. = TRUE)
percentVariance <- pcaObject$sd^2/sum(pcaObject$sd^2)*100
percentVariance[1:3]
head(pcaObject$x[, 1:5])
head(pcaObject$rotation[, 1:3])
trans <- preProcess(segData,
method = c("BoxCox", "center", "scale", "pca"))
trans
transformed <- predict(trans, segData)
head(transformed[, 1:5])
nearZeroVar(segData)
correlations <- cor(segData)
correlations <- cor(segData)
dim(correlations)
correlations[1:4, 1:4]
library(corrplot)
corrplot(correlations, order = "hclust")
corrplot(correlations[1:4, 1:4], order = "hclust")
corrplot(correlations[1:14, 1:14], order = "hclust")
data(twoClassData)
str(predictors)
head(trainingRows)
data(twoClassData)
str(predictors)
str(predictors)
str(classes)
head(trainingRows)
set.seed(1)
trainingRows <- createDataPartition(classes,
p = .80, list= FALSE)
head(trainingRows)
modelFunction(price ~ numBedrooms + numBaths + acres,
data = housingData)
modelFunction(x = housePredictors, y = price)
trainPredictors <- as.matrix(trainPredictors)
set.seed(1)
trainingRows <- createDataPartition(classes,
p = .80, list= FALSE)
head(trainingRows)
trainPredictors <- predictors[trainingRows, ]
trainClasses <- classes[trainingRows]
testPredictors <- predictors[-trainingRows, ]
testClasses <- classes[-trainingRows]
str(trainPredictors)
str(testPredictors)
trainPredictors <- as.matrix(trainPredictors)
knnFit <- knn3(x = trainPredictors, y = trainClasses, k = 5)
knnFit
testPredictions <- predict(knnFit, newdata = testPredictors,
type = "class")
head(testPredictions)
str(testPredictions)
data(GermanCredit)
set.seed(1056)
svmFit <- train(Class ~ .,data = GermanCreditTrain,method = "svmRadial",
preProc = c("center", "scale"))
library(AppliedPredictiveModeling)
data(GermanCredit)
set.seed(1056)
svmFit <- train(Class ~ .,data = GermanCreditTrain,method = "svmRadial",
preProc = c("center", "scale"))
View(transformed)
svmFit <- train(Class ~ .,data = GermanCreditTrain,method = "svmRadial",
preProc = c("center", "scale"))
GermanCreditTrain<-data(GermanCredit)
set.seed(1056)
svmFit <- train(Class ~ .,data = GermanCreditTrain,method = "svmRadial",
preProc = c("center", "scale"))
svmFit <- train(Class ~ .,data = GermanCredit,method = "svmRadial",
preProc = c("center", "scale"))
svmFit
svmFit <- train(Class ~ .,data = GermanCredit,method = "svmRadial",
preProc = c("center", "scale"),tuneLength = 10)
svmFit <- train(Class ~ .,data = GermanCredit,method = "svmRadial",
preProc = c("center", "scale"),tuneLength = 10,
trControl = trainControl(method = "repeatedcv",repeats = 5))
plot(svmFit, scales = list(x = list(log = 2)))
vip(svmFit)
svmvif<-vif(svmFit)
library(car)
svmvif<-vif(svmFit)
data(solubility)
ls(pattern = "^solT")
set.seed(2)
sample(names(solTrainX), 8)
ctrl <- trainControl(method = "cv", number = 10)
trainingData <- solTrainXtrans
trainingData$Solubility <- solTrainY
head(trainingData)
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.001)
plot(ridgeModel)
ridgePred <- predict(ridgeModel, newx = as.matrix(solTestXtrans),
s = 1, mode = "fraction",type = "fit")
library(elasticnet)
library(caret)
library(lars)
library(MASS)
library(pls)
library(stats)
library(AppliedPredictiveModeling)
data(solubility)
ls(pattern = "^solT")
set.seed(2)
sample(names(solTrainX), 8)
ctrl <- trainControl(method = "cv", number = 10)
trainingData <- solTrainXtrans
trainingData$Solubility <- solTrainY
head(trainingData)
ridgeModel <- enet(x = as.matrix(solTrainXtrans),
y = solTrainY,
lambda = 0.001)
plot(ridgeModel)
ridgeVif=vif(ridgeModel)
ridgeVif=vif(trainingData)
ridgePred <- predict(ridgeModel, newx = as.matrix(solTestXtrans),
s = 1, mode = "fraction",type = "fit")
ridgeVif=vif(ridgePred)
